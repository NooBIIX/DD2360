{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **CUDA** \n",
        "Below is an example that runs native CUDA code. \n",
        "\n",
        "1.   We investigate the CUDA version, drivers and the avaiable GPU with nvidia-smi and nvcc-version\n",
        "2.   We use the IPython magic command \"%%writefile filename\" to save a *.cu program\n",
        "3.   We then compile and run the *.cu program with nvcc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q0-ZomlNSrF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJlrROAn5Rqj",
        "outputId": "ec72186e-c152-4b9b-a99f-5d6801a800bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "Mon Jan 16 08:00:22 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Next, we write a native CUDA code and save it as 'vectorAdd.cu'\n"
      ],
      "metadata": {
        "id": "vsbr4brQH6v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0S5AUrl4eI8",
        "outputId": "ce0e1815-7321-494c-9ebc-ac5f29dcaceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We compile the saved cuda code using nvcc compiler"
      ],
      "metadata": {
        "id": "TqdaBa9wIICn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -o vectorAdd\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYps9NQ40NC",
        "outputId": "94e08926-2587-4d75-dfbb-5d7be1d3ba1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vectorAdd\tvectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally, we execute the binary of the compiled code"
      ],
      "metadata": {
        "id": "SUALHJy9IPvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./vectorAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF-iISqy7O2E",
        "outputId": "2a8e668e-d0b7-4d5c-aec7-98b9e47fd644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -I/usr/local/cuda/samples/common/inc vecmul.cu -o vecmul"
      ],
      "metadata": {
        "id": "NDvwDQ5wmAt3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 32 32 32 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD37od5gmj6E",
        "outputId": "19332bad-7971-4b93-81a9-4b366a1283c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (32 x 32) (32 x 32) (32 x 32)\n",
            "==PROF== Connected to process 1109 (/content/vecmul)\n",
            "Transfer time host to device 0.000036 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.695777 seconds\n",
            "Transfer Time device to host 0.000046 seconds\n",
            "==PROF== Disconnected from process 1109\n",
            "[1109] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:13:14, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.94\n",
            "    SM Frequency                                                             cycle/usecond                         579.76\n",
            "    Elapsed Cycles                                                                   cycle                          6,791\n",
            "    Memory [%]                                                                           %                           1.58\n",
            "    SOL DRAM                                                                             %                           0.39\n",
            "    Duration                                                                       usecond                          11.71\n",
            "    SOL L1/TEX Cache                                                                     %                          76.26\n",
            "    SOL L2 Cache                                                                         %                           0.42\n",
            "    SM Active Cycles                                                                 cycle                         140.57\n",
            "    SM [%]                                                                               %                           1.58\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                           1\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                          1,024\n",
            "    Waves Per SM                                                                                                     0.03\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          95.89\n",
            "    Achieved Active Warps Per SM                                                      warp                          30.68\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 128 128 128 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP7WxV7tn5tl",
        "outputId": "5902259a-46da-482b-b789-8dd2cc84e6b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (128 x 128) (128 x 128) (128 x 128)\n",
            "==PROF== Connected to process 964 (/content/vecmul)\n",
            "Transfer time host to device 0.000094 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.637157 seconds\n",
            "Transfer Time device to host 0.000121 seconds\n",
            "==PROF== Disconnected from process 964\n",
            "[964] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:12:50, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.15\n",
            "    Elapsed Cycles                                                                   cycle                         20,248\n",
            "    Memory [%]                                                                           %                          32.76\n",
            "    SOL DRAM                                                                             %                           2.13\n",
            "    Duration                                                                       usecond                          34.59\n",
            "    SOL L1/TEX Cache                                                                     %                          87.40\n",
            "    SOL L2 Cache                                                                         %                           2.05\n",
            "    SM Active Cycles                                                                 cycle                       7,586.12\n",
            "    SM [%]                                                                               %                          32.76\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                          16\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                         16,384\n",
            "    Waves Per SM                                                                                                     0.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 40             \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          97.00\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.04\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 511 1023 1023 4094"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltG6nkx4oYhS",
        "outputId": "a794cae9-0188-49f2-c2a4-d459c10e3533"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (511 x 1023) (1023 x 4094) (511 x 4094)\n",
            "==PROF== Connected to process 2219 (/content/vecmul)\n",
            "Transfer time host to device 0.004398 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.761530 seconds\n",
            "Transfer Time device to host 0.005504 seconds\n",
            "==PROF== Disconnected from process 2219\n",
            "[2219] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:17:50, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.00\n",
            "    Elapsed Cycles                                                                   cycle                      7,948,216\n",
            "    Memory [%]                                                                           %                          84.31\n",
            "    SOL DRAM                                                                             %                          10.32\n",
            "    Duration                                                                       msecond                          13.59\n",
            "    SOL L1/TEX Cache                                                                     %                          87.85\n",
            "    SOL L2 Cache                                                                         %                           5.14\n",
            "    SM Active Cycles                                                                 cycle                   7,840,033.67\n",
            "    SM [%]                                                                               %                          84.31\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       2,048\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      2,097,152\n",
            "    Waves Per SM                                                                                                    51.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.28\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.45\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 1024 2048 2048 4096"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F-DRb_JorPl",
        "outputId": "b367948d-9de7-4560-b31c-01ca6448d217"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (1024 x 2048) (2048 x 4096) (1024 x 4096)\n",
            "==PROF== Connected to process 1197 (/content/vecmul)\n",
            "Transfer time host to device 0.008818 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 1.056773 seconds\n",
            "Transfer Time device to host 0.010558 seconds\n",
            "==PROF== Disconnected from process 1197\n",
            "[1197] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:17:13, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.05\n",
            "    Elapsed Cycles                                                                   cycle                     31,018,086\n",
            "    Memory [%]                                                                           %                          86.60\n",
            "    SOL DRAM                                                                             %                           9.84\n",
            "    Duration                                                                       msecond                          53.02\n",
            "    SOL L1/TEX Cache                                                                     %                          87.08\n",
            "    SOL L2 Cache                                                                         %                           4.67\n",
            "    SM Active Cycles                                                                 cycle                  30,847,159.18\n",
            "    SM [%]                                                                               %                          86.60\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       4,096\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      4,194,304\n",
            "    Waves Per SM                                                                                                   102.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.56\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.54\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 256 256 256 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgVUbsk-qusm",
        "outputId": "9c0af127-d6ad-449e-d699-cf7ba131a8c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (256 x 256) (256 x 256) (256 x 256)\n",
            "==PROF== Connected to process 2323 (/content/vecmul)\n",
            "Transfer time host to device 0.000175 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.683763 seconds\n",
            "Transfer Time device to host 0.000256 seconds\n",
            "==PROF== Disconnected from process 2323\n",
            "[2323] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:17:52, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.98\n",
            "    SM Frequency                                                             cycle/usecond                         582.60\n",
            "    Elapsed Cycles                                                                   cycle                         76,872\n",
            "    Memory [%]                                                                           %                          68.61\n",
            "    SOL DRAM                                                                             %                           2.21\n",
            "    Duration                                                                       usecond                         131.94\n",
            "    SOL L1/TEX Cache                                                                     %                          87.25\n",
            "    SOL L2 Cache                                                                         %                           3.89\n",
            "    SM Active Cycles                                                                 cycle                      60,445.35\n",
            "    SM [%]                                                                               %                          68.61\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. \n",
            "          Check both the Compute Workload Analysis and Memory Workload Analysis report sections.                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                          64\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                         65,536\n",
            "    Waves Per SM                                                                                                     1.60\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the \n",
            "          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   \n",
            "          hardware busy.                                                                                                \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          97.84\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.31\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 512 512 512 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v1cFArDq4Ag",
        "outputId": "43550b36-c60c-49a2-9aef-35a76e9de0e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (512 x 512) (512 x 512) (512 x 512)\n",
            "==PROF== Connected to process 2347 (/content/vecmul)\n",
            "Transfer time host to device 0.000556 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.679272 seconds\n",
            "Transfer Time device to host 0.000802 seconds\n",
            "==PROF== Disconnected from process 2347\n",
            "[2347] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:17:54, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.25\n",
            "    Elapsed Cycles                                                                   cycle                        516,879\n",
            "    Memory [%]                                                                           %                          81.38\n",
            "    SOL DRAM                                                                             %                           1.29\n",
            "    Duration                                                                       usecond                         883.17\n",
            "    SOL L1/TEX Cache                                                                     %                          89.32\n",
            "    SOL L2 Cache                                                                         %                           4.48\n",
            "    SM Active Cycles                                                                 cycle                     470,959.95\n",
            "    SM [%]                                                                               %                          81.38\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         256\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        262,144\n",
            "    Waves Per SM                                                                                                     6.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.13\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 1024 1024 1024 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPDkBdEpq84I",
        "outputId": "fd10fa9b-35c9-43ee-f3e4-7322eed54941"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (1024 x 1024) (1024 x 1024) (1024 x 1024)\n",
            "==PROF== Connected to process 2379 (/content/vecmul)\n",
            "Transfer time host to device 0.002058 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.704722 seconds\n",
            "Transfer Time device to host 0.002732 seconds\n",
            "==PROF== Disconnected from process 2379\n",
            "[2379] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:18:08, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         584.88\n",
            "    Elapsed Cycles                                                                   cycle                      3,897,031\n",
            "    Memory [%]                                                                           %                          86.23\n",
            "    SOL DRAM                                                                             %                           7.25\n",
            "    Duration                                                                       msecond                           6.66\n",
            "    SOL L1/TEX Cache                                                                     %                          87.78\n",
            "    SOL L2 Cache                                                                         %                           4.68\n",
            "    SM Active Cycles                                                                 cycle                   3,827,945.35\n",
            "    SM [%]                                                                               %                          86.23\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       1,024\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      1,048,576\n",
            "    Waves Per SM                                                                                                    25.60\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.41\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.49\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 2048 2048 2048 2048"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1H1ZIaOrEww",
        "outputId": "977ca5ae-7d5c-4d93-8f1a-110de941603a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (2048 x 2048) (2048 x 2048) (2048 x 2048)\n",
            "==PROF== Connected to process 2459 (/content/vecmul)\n",
            "Transfer time host to device 0.007310 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 1.060314 seconds\n",
            "Transfer Time device to host 0.010693 seconds\n",
            "==PROF== Disconnected from process 2459\n",
            "[2459] vecmul@127.0.0.1\n",
            "  gemm(float*, float*, float*, int, int, int, int), 2023-Jan-16 19:20:10, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.30\n",
            "    Elapsed Cycles                                                                   cycle                     31,022,873\n",
            "    Memory [%]                                                                           %                          86.59\n",
            "    SOL DRAM                                                                             %                           9.94\n",
            "    Duration                                                                       msecond                          53.00\n",
            "    SOL L1/TEX Cache                                                                     %                          87.09\n",
            "    SOL L2 Cache                                                                         %                           4.66\n",
            "    SM Active Cycles                                                                 cycle                  30,844,390.32\n",
            "    SM [%]                                                                               %                          86.59\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       4,096\n",
            "    Registers Per Thread                                                   register/thread                             49\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      4,194,304\n",
            "    Waves Per SM                                                                                                   102.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.56\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.54\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}