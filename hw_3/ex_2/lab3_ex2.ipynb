{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **CUDA** \n",
        "Below is an example that runs native CUDA code. \n",
        "\n",
        "1.   We investigate the CUDA version, drivers and the avaiable GPU with nvidia-smi and nvcc-version\n",
        "2.   We use the IPython magic command \"%%writefile filename\" to save a *.cu program\n",
        "3.   We then compile and run the *.cu program with nvcc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q0-ZomlNSrF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJlrROAn5Rqj",
        "outputId": "ec72186e-c152-4b9b-a99f-5d6801a800bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "Mon Jan 16 08:00:22 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Next, we write a native CUDA code and save it as 'vectorAdd.cu'\n"
      ],
      "metadata": {
        "id": "vsbr4brQH6v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0S5AUrl4eI8",
        "outputId": "ce0e1815-7321-494c-9ebc-ac5f29dcaceb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We compile the saved cuda code using nvcc compiler"
      ],
      "metadata": {
        "id": "TqdaBa9wIICn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -o vectorAdd\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYps9NQ40NC",
        "outputId": "94e08926-2587-4d75-dfbb-5d7be1d3ba1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vectorAdd\tvectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally, we execute the binary of the compiled code"
      ],
      "metadata": {
        "id": "SUALHJy9IPvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./vectorAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF-iISqy7O2E",
        "outputId": "2a8e668e-d0b7-4d5c-aec7-98b9e47fd644"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -I/usr/local/cuda/samples/common/inc lab3_ex2_template.cu -o vecmul"
      ],
      "metadata": {
        "id": "NDvwDQ5wmAt3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 32 32 32 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD37od5gmj6E",
        "outputId": "e863172b-abc4-46c3-ab56-a570791d9bbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (32 x 32) (32 x 32) (32 x 32)\n",
            "==PROF== Connected to process 2586 (/content/vecmul)\n",
            "Transfer time host to device 0.000045 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.776861 seconds\n",
            "Transfer Time device to host 0.000049 seconds\n",
            "==PROF== Disconnected from process 2586\n",
            "[2586] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:07:03, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.96\n",
            "    SM Frequency                                                             cycle/usecond                         580.71\n",
            "    Elapsed Cycles                                                                   cycle                         20,349\n",
            "    Memory [%]                                                                           %                           0.53\n",
            "    SOL DRAM                                                                             %                           0.24\n",
            "    Duration                                                                       usecond                          35.04\n",
            "    SOL L1/TEX Cache                                                                     %                          22.31\n",
            "    SOL L2 Cache                                                                         %                           0.17\n",
            "    SM Active Cycles                                                                 cycle                         480.48\n",
            "    SM [%]                                                                               %                           2.01\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                           1\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                          1,024\n",
            "    Waves Per SM                                                                                                     0.03\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          92.29\n",
            "    Achieved Active Warps Per SM                                                      warp                          29.53\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 128 128 128 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP7WxV7tn5tl",
        "outputId": "fb72c691-5c48-49ef-f410-98abd383fca2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (128 x 128) (128 x 128) (128 x 128)\n",
            "==PROF== Connected to process 3466 (/content/vecmul)\n",
            "Transfer time host to device 0.000117 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.668961 seconds\n",
            "Transfer Time device to host 0.000125 seconds\n",
            "==PROF== Disconnected from process 3466\n",
            "[3466] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:10:35, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.71\n",
            "    Elapsed Cycles                                                                   cycle                         71,413\n",
            "    Memory [%]                                                                           %                           9.29\n",
            "    SOL DRAM                                                                             %                           1.14\n",
            "    Duration                                                                       usecond                         121.92\n",
            "    SOL L1/TEX Cache                                                                     %                          23.70\n",
            "    SOL L2 Cache                                                                         %                           1.14\n",
            "    SM Active Cycles                                                                 cycle                      27,972.42\n",
            "    SM [%]                                                                               %                          36.71\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                          16\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                         16,384\n",
            "    Waves Per SM                                                                                                     0.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 40             \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          96.25\n",
            "    Achieved Active Warps Per SM                                                      warp                          30.80\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 511 1023 1023 4094"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltG6nkx4oYhS",
        "outputId": "20616beb-81da-418a-f1cf-de69c2e83c38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (511 x 1023) (1023 x 4094) (511 x 4094)\n",
            "==PROF== Connected to process 3616 (/content/vecmul)\n",
            "Transfer time host to device 0.008077 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 1.039614 seconds\n",
            "Transfer Time device to host 0.010823 seconds\n",
            "==PROF== Disconnected from process 3616\n",
            "[3616] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:11:37, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.99\n",
            "    SM Frequency                                                             cycle/usecond                         584.87\n",
            "    Elapsed Cycles                                                                   cycle                     28,111,915\n",
            "    Memory [%]                                                                           %                          25.31\n",
            "    SOL DRAM                                                                             %                           5.41\n",
            "    Duration                                                                       msecond                          48.07\n",
            "    SOL L1/TEX Cache                                                                     %                          50.61\n",
            "    SOL L2 Cache                                                                         %                           2.91\n",
            "    SM Active Cycles                                                                 cycle                  27,718,192.48\n",
            "    SM [%]                                                                               %                          95.21\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       2,048\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      2,097,152\n",
            "    Waves Per SM                                                                                                    51.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.57\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.54\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 1024 2048 2048 4096"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F-DRb_JorPl",
        "outputId": "c3a6584d-b616-4c5e-b115-06179d0d5b87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (1024 x 2048) (2048 x 4096) (1024 x 4096)\n",
            "==PROF== Connected to process 4737 (/content/vecmul)\n",
            "Transfer time host to device 0.018661 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 2.194466 seconds\n",
            "Transfer Time device to host 0.021263 seconds\n",
            "==PROF== Disconnected from process 4737\n",
            "[4737] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:20:25, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         584.99\n",
            "    Elapsed Cycles                                                                   cycle                    111,637,768\n",
            "    Memory [%]                                                                           %                          24.06\n",
            "    SOL DRAM                                                                             %                           4.86\n",
            "    Duration                                                                       msecond                         190.84\n",
            "    SOL L1/TEX Cache                                                                     %                          48.12\n",
            "    SOL L2 Cache                                                                         %                           2.65\n",
            "    SM Active Cycles                                                                 cycle                 111,007,395.25\n",
            "    SM [%]                                                                               %                          96.18\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       4,096\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      4,194,304\n",
            "    Waves Per SM                                                                                                   102.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.85\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.63\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 256 256 256 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgVUbsk-qusm",
        "outputId": "7f0f95a2-15f4-4129-9b5a-fd1fab4dee54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (256 x 256) (256 x 256) (256 x 256)\n",
            "==PROF== Connected to process 6269 (/content/vecmul)\n",
            "Transfer time host to device 0.000326 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.640931 seconds\n",
            "Transfer Time device to host 0.000403 seconds\n",
            "==PROF== Disconnected from process 6269\n",
            "[6269] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:21:36, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.99\n",
            "    SM Frequency                                                             cycle/usecond                         584.75\n",
            "    Elapsed Cycles                                                                   cycle                        277,878\n",
            "    Memory [%]                                                                           %                          18.98\n",
            "    SOL DRAM                                                                             %                           1.14\n",
            "    Duration                                                                       usecond                         475.20\n",
            "    SOL L1/TEX Cache                                                                     %                          37.92\n",
            "    SOL L2 Cache                                                                         %                           2.15\n",
            "    SM Active Cycles                                                                 cycle                     221,204.20\n",
            "    SM [%]                                                                               %                          75.47\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     \n",
            "          what the compute pipelines are spending their time doing. Also, consider whether any computation is           \n",
            "          redundant and could be reduced or moved to look-up tables.                                                    \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                          64\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                         65,536\n",
            "    Waves Per SM                                                                                                     1.60\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the \n",
            "          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   \n",
            "          hardware busy.                                                                                                \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          97.81\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.30\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 512 512 512 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v1cFArDq4Ag",
        "outputId": "c39fc381-ca39-48b8-8e9b-4bf025b193ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (512 x 512) (512 x 512) (512 x 512)\n",
            "==PROF== Connected to process 6365 (/content/vecmul)\n",
            "Transfer time host to device 0.001008 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.649788 seconds\n",
            "Transfer Time device to host 0.001399 seconds\n",
            "==PROF== Disconnected from process 6365\n",
            "[6365] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:21:56, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.99\n",
            "    SM Frequency                                                             cycle/usecond                         584.84\n",
            "    Elapsed Cycles                                                                   cycle                      1,911,386\n",
            "    Memory [%]                                                                           %                          22.01\n",
            "    SOL DRAM                                                                             %                           0.79\n",
            "    Duration                                                                       msecond                           3.27\n",
            "    SOL L1/TEX Cache                                                                     %                          43.99\n",
            "    SOL L2 Cache                                                                         %                           2.42\n",
            "    SM Active Cycles                                                                 cycle                   1,746,546.95\n",
            "    SM [%]                                                                               %                          87.78\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         256\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        262,144\n",
            "    Waves Per SM                                                                                                     6.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.64\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.57\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 1024 1024 1024 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPDkBdEpq84I",
        "outputId": "00c88159-13a7-4ff2-b677-b27364bcc884"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (1024 x 1024) (1024 x 1024) (1024 x 1024)\n",
            "==PROF== Connected to process 6473 (/content/vecmul)\n",
            "Transfer time host to device 0.003775 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 0.825443 seconds\n",
            "Transfer Time device to host 0.005415 seconds\n",
            "==PROF== Disconnected from process 6473\n",
            "[6473] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:22:28, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         584.91\n",
            "    Elapsed Cycles                                                                   cycle                     14,119,300\n",
            "    Memory [%]                                                                           %                          23.80\n",
            "    SOL DRAM                                                                             %                           4.07\n",
            "    Duration                                                                       msecond                          24.14\n",
            "    SOL L1/TEX Cache                                                                     %                          47.59\n",
            "    SOL L2 Cache                                                                         %                           2.59\n",
            "    SM Active Cycles                                                                 cycle                  13,900,808.12\n",
            "    SM [%]                                                                               %                          95.06\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       1,024\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      1,048,576\n",
            "    Waves Per SM                                                                                                    25.60\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.80\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.62\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecmul 2048 2048 2048 2048"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1H1ZIaOrEww",
        "outputId": "7b0ce9e1-fc22-43b8-85d3-be3cd6b64719"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dim (2048 x 2048) (2048 x 2048) (2048 x 2048)\n",
            "==PROF== Connected to process 6631 (/content/vecmul)\n",
            "Transfer time host to device 0.015762 seconds\n",
            "==PROF== Profiling \"gemm\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel Time 2.196003 seconds\n",
            "Transfer Time device to host 0.026331 seconds\n",
            "==PROF== Disconnected from process 6631\n",
            "[6631] vecmul@127.0.0.1\n",
            "  gemm(double*, double*, double*, int, int, int, int), 2023-Jan-16 08:27:05, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.00\n",
            "    Elapsed Cycles                                                                   cycle                    111,632,411\n",
            "    Memory [%]                                                                           %                          24.06\n",
            "    SOL DRAM                                                                             %                           4.91\n",
            "    Duration                                                                       msecond                         190.82\n",
            "    SOL L1/TEX Cache                                                                     %                          48.12\n",
            "    SOL L2 Cache                                                                         %                           2.63\n",
            "    SM Active Cycles                                                                 cycle                 111,001,964.55\n",
            "    SM [%]                                                                               %                          96.19\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       4,096\n",
            "    Registers Per Thread                                                   register/thread                             62\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      4,194,304\n",
            "    Waves Per SM                                                                                                   102.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              1\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          98.85\n",
            "    Achieved Active Warps Per SM                                                      warp                          31.63\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}