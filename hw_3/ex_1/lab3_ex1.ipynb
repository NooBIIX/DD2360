{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **CUDA** \n",
        "Below is an example that runs native CUDA code. \n",
        "\n",
        "1.   We investigate the CUDA version, drivers and the avaiable GPU with nvidia-smi and nvcc-version\n",
        "2.   We use the IPython magic command \"%%writefile filename\" to save a *.cu program\n",
        "3.   We then compile and run the *.cu program with nvcc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q0-ZomlNSrF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJlrROAn5Rqj",
        "outputId": "9bee6a6d-23b4-4ade-f998-a3501db943a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "Sun Jan 15 23:41:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Next, we write a native CUDA code and save it as 'vectorAdd.cu'\n"
      ],
      "metadata": {
        "id": "vsbr4brQH6v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0S5AUrl4eI8",
        "outputId": "279f9180-494e-4126-872a-3bb05acc676c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We compile the saved cuda code using nvcc compiler"
      ],
      "metadata": {
        "id": "TqdaBa9wIICn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -o vectorAdd\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYps9NQ40NC",
        "outputId": "5cce6f4d-3ae2-45e4-e994-137c15a1da70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vectorAdd\tvectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally, we execute the binary of the compiled code"
      ],
      "metadata": {
        "id": "SUALHJy9IPvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./vectorAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF-iISqy7O2E",
        "outputId": "2a6f3f36-9b7b-4f14-e859-521d930a2ae4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -I/usr/local/cuda/samples/common/inc lab3_ex1_template.cu -o vecadd"
      ],
      "metadata": {
        "id": "kmCLF8gsz51A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrHiosi2z6Cb",
        "outputId": "504fd494-e5e4-4c54-c1a5-595930760b08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1024\n",
            "==PROF== Connected to process 1405 (/content/vecadd)\n",
            "Transfer time host to device 0.000056 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.782115 seconds\n",
            "Transfer time device to host 0.000052 seconds\n",
            "==PROF== Disconnected from process 1405\n",
            "[1405] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-15 23:44:29, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.93\n",
            "    SM Frequency                                                             cycle/usecond                         576.11\n",
            "    Elapsed Cycles                                                                   cycle                          3,005\n",
            "    Memory [%]                                                                           %                           1.24\n",
            "    SOL DRAM                                                                             %                           1.24\n",
            "    Duration                                                                       usecond                           5.22\n",
            "    SOL L1/TEX Cache                                                                     %                          27.69\n",
            "    SOL L2 Cache                                                                         %                           0.82\n",
            "    SM Active Cycles                                                                 cycle                          46.23\n",
            "    SM [%]                                                                               %                           0.43\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                           1\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                          1,024\n",
            "    Waves Per SM                                                                                                     0.03\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 40              \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          82.07\n",
            "    Achieved Active Warps Per SM                                                      warp                          26.26\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 131070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yFiMnmvz6FC",
        "outputId": "22d88071-e917-4320-aefd-cda03006fdaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 131070\n",
            "==PROF== Connected to process 2281 (/content/vecadd)\n",
            "Transfer time host to device 0.001014 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.659832 seconds\n",
            "Transfer time device to host 0.001259 seconds\n",
            "==PROF== Disconnected from process 2281\n",
            "[2281] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-15 23:48:00, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.91\n",
            "    SM Frequency                                                             cycle/usecond                         573.62\n",
            "    Elapsed Cycles                                                                   cycle                          8,316\n",
            "    Memory [%]                                                                           %                          51.06\n",
            "    SOL DRAM                                                                             %                          51.06\n",
            "    Duration                                                                       usecond                          14.50\n",
            "    SOL L1/TEX Cache                                                                     %                          27.56\n",
            "    SOL L2 Cache                                                                         %                          25.59\n",
            "    SM Active Cycles                                                                 cycle                          5,944\n",
            "    SM [%]                                                                               %                          19.70\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         128\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        131,072\n",
            "    Waves Per SM                                                                                                     3.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    \n",
            "          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       \n",
            "          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 8 thread blocks.    \n",
            "          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   \n",
            "          up to 25.0% of the total kernel runtime with a lower occupancy of 22.5%. Try launching a grid with no         \n",
            "          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  \n",
            "          a grid.                                                                                                       \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          77.53\n",
            "    Achieved Active Warps Per SM                                                      warp                          24.81\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 204800"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43glSGOR4EQD",
        "outputId": "9998a171-5d14-4c15-f641-a33969850c6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 204800\n",
            "==PROF== Connected to process 5301 (/content/vecadd)\n",
            "Transfer time host to device 0.001468 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.661228 seconds\n",
            "Transfer time device to host 0.001700 seconds\n",
            "==PROF== Disconnected from process 5301\n",
            "[5301] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-16 00:00:31, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.02\n",
            "    SM Frequency                                                             cycle/usecond                         587.43\n",
            "    Elapsed Cycles                                                                   cycle                         11,263\n",
            "    Memory [%]                                                                           %                          61.80\n",
            "    SOL DRAM                                                                             %                          61.80\n",
            "    Duration                                                                       usecond                          19.17\n",
            "    SOL L1/TEX Cache                                                                     %                          29.96\n",
            "    SOL L2 Cache                                                                         %                          29.40\n",
            "    SM Active Cycles                                                                 cycle                       8,543.52\n",
            "    SM [%]                                                                               %                          22.74\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      \n",
            "          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           \n",
            "          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  \n",
            "          access (kernel fusion) or whether there are values you can (re)compute.                                       \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         200\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        204,800\n",
            "    Waves Per SM                                                                                                        5\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          77.29\n",
            "    Achieved Active Warps Per SM                                                      warp                          24.73\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 409600"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8osGyKne4N3W",
        "outputId": "b6049543-6c62-443f-a0fc-6d993743e3a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 409600\n",
            "==PROF== Connected to process 5479 (/content/vecadd)\n",
            "Transfer time host to device 0.002619 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.636049 seconds\n",
            "Transfer time device to host 0.003388 seconds\n",
            "==PROF== Disconnected from process 5479\n",
            "[5479] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-16 00:01:09, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.97\n",
            "    SM Frequency                                                             cycle/usecond                         582.89\n",
            "    Elapsed Cycles                                                                   cycle                         21,547\n",
            "    Memory [%]                                                                           %                          75.98\n",
            "    SOL DRAM                                                                             %                          75.98\n",
            "    Duration                                                                       usecond                          36.96\n",
            "    SOL L1/TEX Cache                                                                     %                          29.88\n",
            "    SOL L2 Cache                                                                         %                          30.62\n",
            "    SM Active Cycles                                                                 cycle                      17,878.95\n",
            "    SM [%]                                                                               %                          23.77\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      \n",
            "          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           \n",
            "          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  \n",
            "          access (kernel fusion) or whether there are values you can (re)compute.                                       \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         400\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        409,600\n",
            "    Waves Per SM                                                                                                       10\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          79.66\n",
            "    Achieved Active Warps Per SM                                                      warp                          25.49\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 512000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy6d3Bnq4dZa",
        "outputId": "7c3cfc05-c347-457d-a7a4-5baa03c10616"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 512000\n",
            "==PROF== Connected to process 5825 (/content/vecadd)\n",
            "Transfer time host to device 0.003181 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.631751 seconds\n",
            "Transfer time device to host 0.003872 seconds\n",
            "==PROF== Disconnected from process 5825\n",
            "[5825] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-16 00:02:29, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.98\n",
            "    SM Frequency                                                             cycle/usecond                         584.05\n",
            "    Elapsed Cycles                                                                   cycle                         26,729\n",
            "    Memory [%]                                                                           %                          78.85\n",
            "    SOL DRAM                                                                             %                          78.85\n",
            "    Duration                                                                       usecond                          45.76\n",
            "    SOL L1/TEX Cache                                                                     %                          30.08\n",
            "    SOL L2 Cache                                                                         %                          30.83\n",
            "    SM Active Cycles                                                                 cycle                      22,422.85\n",
            "    SM [%]                                                                               %                          23.95\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      \n",
            "          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           \n",
            "          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  \n",
            "          access (kernel fusion) or whether there are values you can (re)compute.                                       \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         500\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        512,000\n",
            "    Waves Per SM                                                                                                    12.50\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          80.18\n",
            "    Achieved Active Warps Per SM                                                      warp                          25.66\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 819200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GZPXXRZ4spi",
        "outputId": "7cfa462d-c11e-481d-8b73-6a2e655acaab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 819200\n",
            "==PROF== Connected to process 5975 (/content/vecadd)\n",
            "Transfer time host to device 0.005082 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.673848 seconds\n",
            "Transfer time device to host 0.006751 seconds\n",
            "==PROF== Disconnected from process 5975\n",
            "[5975] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-16 00:03:00, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.99\n",
            "    SM Frequency                                                             cycle/usecond                         584.71\n",
            "    Elapsed Cycles                                                                   cycle                         42,571\n",
            "    Memory [%]                                                                           %                          83.30\n",
            "    SOL DRAM                                                                             %                          83.30\n",
            "    Duration                                                                       usecond                          72.80\n",
            "    SOL L1/TEX Cache                                                                     %                          30.20\n",
            "    SOL L2 Cache                                                                         %                          30.93\n",
            "    SM Active Cycles                                                                 cycle                      37,013.05\n",
            "    SM [%]                                                                               %                          24.06\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Memory Workload Analysis section.                                         \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         800\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        819,200\n",
            "    Waves Per SM                                                                                                       20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          81.16\n",
            "    Achieved Active Warps Per SM                                                      warp                          25.97\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 1000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W-zFic24wNm",
        "outputId": "6ccaf39a-fdc6-42d7-b5d2-099c96eaf9b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1000000\n",
            "==PROF== Connected to process 6221 (/content/vecadd)\n",
            "Transfer time host to device 0.006085 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.667252 seconds\n",
            "Transfer time device to host 0.007503 seconds\n",
            "==PROF== Disconnected from process 6221\n",
            "[6221] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-16 00:03:54, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.99\n",
            "    SM Frequency                                                             cycle/usecond                         584.21\n",
            "    Elapsed Cycles                                                                   cycle                         51,733\n",
            "    Memory [%]                                                                           %                          85.56\n",
            "    SOL DRAM                                                                             %                          85.56\n",
            "    Duration                                                                       usecond                          88.54\n",
            "    SOL L1/TEX Cache                                                                     %                          30.35\n",
            "    SOL L2 Cache                                                                         %                          31.06\n",
            "    SM Active Cycles                                                                 cycle                      45,827.68\n",
            "    SM [%]                                                                               %                          24.16\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Memory Workload Analysis section.                                         \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         977\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      1,000,448\n",
            "    Waves Per SM                                                                                                    24.43\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          81.53\n",
            "    Achieved Active Warps Per SM                                                      warp                          26.09\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./vecadd 2000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWnH8q2U49pb",
        "outputId": "26a5fef5-0ea9-4e9c-c984-013ffa2061af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 2000000\n",
            "==PROF== Connected to process 6295 (/content/vecadd)\n",
            "Transfer time host to device 0.012094 seconds\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Kernel time 0.645282 seconds\n",
            "Transfer time device to host 0.015182 seconds\n",
            "==PROF== Disconnected from process 6295\n",
            "[6295] vecadd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2023-Jan-16 00:04:07, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.00\n",
            "    SM Frequency                                                             cycle/usecond                         585.08\n",
            "    Elapsed Cycles                                                                   cycle                        105,094\n",
            "    Memory [%]                                                                           %                          87.57\n",
            "    SOL DRAM                                                                             %                          87.57\n",
            "    Duration                                                                       usecond                         179.62\n",
            "    SOL L1/TEX Cache                                                                     %                          29.89\n",
            "    SOL L2 Cache                                                                         %                          30.55\n",
            "    SM Active Cycles                                                                 cycle                      95,243.15\n",
            "    SM [%]                                                                               %                          23.79\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
            "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
            "          Start by analyzing workloads in the Memory Workload Analysis section.                                         \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       1,954\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                      2,000,896\n",
            "    Waves Per SM                                                                                                    48.85\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          82.51\n",
            "    Achieved Active Warps Per SM                                                      warp                          26.40\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}